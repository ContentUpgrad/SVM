{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear SVM - Email Spam Classifier\n",
    "\n",
    "\n",
    "In this section, we'll build a non-linear SVM classifier to classify emails and compare the performance with the linear SVM model.\n",
    "\n",
    "The dataset can be downloaded here: https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "\n",
    "To reiterate, the performance of the linear model was as follows:\n",
    "- accuracy 0.93\n",
    "- precision 0.92\n",
    "- recall 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will build a non-linear model (using non-linear kernels) and then find the optimal hyperparameters (the choice of kernel, C, gamma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_rec = pd.read_csv(\"Spam (1).csv\",  sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# splitting into X and y\n",
    "X = email_rec.drop(\"spam\", axis = 1)\n",
    "y = email_rec.spam.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaling the features\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using rbf kernel, C=1, default value of gamma\n",
    "\n",
    "model = SVC(C = 1, kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[811,  38],\n",
       "       [ 61, 471]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.928312816799\n",
      "precision 0.925343811395\n",
      "recall 0.885338345865\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# precision\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# recall/sensitivity\n",
    "print(\"recall\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning \n",
    "\n",
    "Now, we have multiple hyperparameters to optimise - \n",
    "- The choice of kernel (linear, rbf etc.)\n",
    "- C\n",
    "- gamma\n",
    "\n",
    "We'll use the ```GridSearchCV()``` method to tune the hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search to Find Optimal Hyperparameters\n",
    "\n",
    "Let's first use the RBF kernel to find the optimal C and gamma (we can consider the kernel as a hyperparameter as well, though training the model will take an exorbitant amount of time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   50.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=4, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a KFold object with 5 splits \n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# specify range of hyperparameters\n",
    "# Set the parameters by cross-validation\n",
    "hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# specify model\n",
    "model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = model, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'accuracy', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.517946</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>0.929814</td>\n",
       "      <td>0.941304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.943323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.945264</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.937888</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.068217</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.473316</td>\n",
       "      <td>0.092060</td>\n",
       "      <td>0.904037</td>\n",
       "      <td>0.906522</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.886646</td>\n",
       "      <td>0.910326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.895963</td>\n",
       "      <td>0.906056</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.904115</td>\n",
       "      <td>0.026618</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.002672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.805738</td>\n",
       "      <td>0.166712</td>\n",
       "      <td>0.786025</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>12</td>\n",
       "      <td>0.770186</td>\n",
       "      <td>0.789208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.785326</td>\n",
       "      <td>0.765528</td>\n",
       "      <td>0.791925</td>\n",
       "      <td>0.799689</td>\n",
       "      <td>0.788820</td>\n",
       "      <td>0.033485</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278786</td>\n",
       "      <td>0.046831</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.964752</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.967003</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.961568</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.333622</td>\n",
       "      <td>0.053636</td>\n",
       "      <td>0.928261</td>\n",
       "      <td>0.934472</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.936335</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.935171</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>0.931289</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.451701</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.905745</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883540</td>\n",
       "      <td>0.909938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899068</td>\n",
       "      <td>0.908773</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.905280</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>0.902562</td>\n",
       "      <td>0.053771</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.003158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.426285</td>\n",
       "      <td>0.049633</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.981910</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.034520</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.331622</td>\n",
       "      <td>0.045830</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.946817</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.950311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.939829</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.003835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.340226</td>\n",
       "      <td>0.059240</td>\n",
       "      <td>0.927019</td>\n",
       "      <td>0.931910</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.917702</td>\n",
       "      <td>0.934006</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.929348</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.523549</td>\n",
       "      <td>0.032022</td>\n",
       "      <td>0.918323</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.01}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.908385</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>0.992624</td>\n",
       "      <td>0.916149</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.054909</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.948431</td>\n",
       "      <td>0.074650</td>\n",
       "      <td>0.933851</td>\n",
       "      <td>0.965761</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.001}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930124</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.963121</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.058539</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.001331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.412275</td>\n",
       "      <td>0.056638</td>\n",
       "      <td>0.929193</td>\n",
       "      <td>0.939441</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1000, 'gamma': 0.0001}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>0.940606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925466</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.021471</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0        0.517946         0.088059         0.929814          0.941304       1   \n",
       "1        0.473316         0.092060         0.904037          0.906522       1   \n",
       "2        0.805738         0.166712         0.786025          0.786957       1   \n",
       "3        0.278786         0.046831         0.933230          0.964752      10   \n",
       "4        0.333622         0.053636         0.928261          0.934472      10   \n",
       "5        0.451701         0.093662         0.902174          0.905745      10   \n",
       "6        0.426285         0.049633         0.931677          0.981910     100   \n",
       "7        0.331622         0.045830         0.933851          0.946817     100   \n",
       "8        0.340226         0.059240         0.927019          0.931910     100   \n",
       "9        0.523549         0.032022         0.918323          0.992857    1000   \n",
       "10       0.948431         0.074650         0.933851          0.965761    1000   \n",
       "11       0.412275         0.056638         0.929193          0.939441    1000   \n",
       "\n",
       "   param_gamma                        params  rank_test_score  \\\n",
       "0         0.01       {'C': 1, 'gamma': 0.01}                5   \n",
       "1        0.001      {'C': 1, 'gamma': 0.001}               10   \n",
       "2       0.0001     {'C': 1, 'gamma': 0.0001}               12   \n",
       "3         0.01      {'C': 10, 'gamma': 0.01}                3   \n",
       "4        0.001     {'C': 10, 'gamma': 0.001}                7   \n",
       "5       0.0001    {'C': 10, 'gamma': 0.0001}               11   \n",
       "6         0.01     {'C': 100, 'gamma': 0.01}                4   \n",
       "7        0.001    {'C': 100, 'gamma': 0.001}                1   \n",
       "8       0.0001   {'C': 100, 'gamma': 0.0001}                8   \n",
       "9         0.01    {'C': 1000, 'gamma': 0.01}                9   \n",
       "10       0.001   {'C': 1000, 'gamma': 0.001}                1   \n",
       "11      0.0001  {'C': 1000, 'gamma': 0.0001}                6   \n",
       "\n",
       "    split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0            0.917702            0.943323       ...                  0.922360   \n",
       "1            0.886646            0.910326       ...                  0.899068   \n",
       "2            0.770186            0.789208       ...                  0.791925   \n",
       "3            0.909938            0.966227       ...                  0.934783   \n",
       "4            0.917702            0.937112       ...                  0.916149   \n",
       "5            0.883540            0.909938       ...                  0.899068   \n",
       "6            0.913043            0.982531       ...                  0.934783   \n",
       "7            0.923913            0.950311       ...                  0.925466   \n",
       "8            0.919255            0.934006       ...                  0.917702   \n",
       "9            0.908385            0.993789       ...                  0.920807   \n",
       "10           0.919255            0.966615       ...                  0.930124   \n",
       "11           0.920807            0.940606       ...                  0.925466   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0             0.945264           0.931677            0.937112   \n",
       "1             0.908773           0.895963            0.906056   \n",
       "2             0.785326           0.765528            0.791925   \n",
       "3             0.967003           0.934783            0.961568   \n",
       "4             0.936335           0.933230            0.935171   \n",
       "5             0.908773           0.892857            0.905280   \n",
       "6             0.982531           0.930124            0.982143   \n",
       "7             0.948758           0.933230            0.945652   \n",
       "8             0.934006           0.928571            0.930901   \n",
       "9             0.992624           0.916149            0.993012   \n",
       "10            0.966615           0.933230            0.963121   \n",
       "11            0.940994           0.928571            0.937112   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0            0.937888            0.939829      0.068217        0.010282   \n",
       "1            0.919255            0.904115      0.026618        0.010106   \n",
       "2            0.799689            0.788820      0.033485        0.022167   \n",
       "3            0.942547            0.962345      0.018749        0.006528   \n",
       "4            0.939441            0.931289      0.031514        0.002873   \n",
       "5            0.920807            0.902562      0.053771        0.013831   \n",
       "6            0.942547            0.982531      0.034520        0.011278   \n",
       "7            0.945652            0.939829      0.011748        0.002137   \n",
       "8            0.934783            0.929348      0.037297        0.005496   \n",
       "9            0.923913            0.992236      0.054909        0.002758   \n",
       "10           0.942547            0.966227      0.058539        0.004131   \n",
       "11           0.934783            0.937500      0.021471        0.004227   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "0         0.008528         0.002814  \n",
       "1         0.013080         0.002672  \n",
       "2         0.015322         0.004277  \n",
       "3         0.012266         0.002308  \n",
       "4         0.009491         0.002242  \n",
       "5         0.013749         0.003158  \n",
       "6         0.010159         0.001059  \n",
       "7         0.008482         0.003835  \n",
       "8         0.007349         0.001831  \n",
       "9         0.005607         0.000527  \n",
       "10        0.009033         0.001331  \n",
       "11        0.005777         0.001753  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.80, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot reveals some interesting insights:\n",
    "- **High values of gamma** lead to **overfitting** (especially at high values of C); note that the training accuracy at gamma=0.01 and C=1000 reaches almost 99% \n",
    "- The **training score increases with higher gamma**, though the **test scores are comparable** (at sufficiently high cost, i.e. C > 10)\n",
    "- The least amount of overfitting (i.e. difference between train and test accuracy) occurs at low gamma, i.e. a quite *simple non-linear model*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.9338509316770186 corresponding to hyperparameters {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though sklearn suggests the optimal scores mentioned above (gamma=0.001, C=100), one could argue that it is better to choose a simpler, more non-linear model with gamma=0.0001. This is because the optimal values mentioned here are calculated based on the average test accuracy (but not considering subjective parameters such as model complexity).\n",
    "\n",
    "We can achieve comparable average test accuracy (~92.5%) with gamma=0.0001 as well, though we'll have to increase the cost C for that. So to achieve high accuracy, there's a tradeoff between:\n",
    "- High gamma (i.e. high non-linearity) and average value of C\n",
    "- Low gamma (i.e. less non-linearity) and high value of C\n",
    "\n",
    "We argue that the model will be simpler if it has as less non-linearity as possible, so we choose gamma=0.0001 and a high C=100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Evaluating the Final Model\n",
    "\n",
    "Let's now build and evaluate the final model, i.e. the model with highest test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[810  39]\n",
      " [ 60 472]] \n",
      "\n",
      "accuracy 0.928312816799\n",
      "precision 0.923679060665\n",
      "sensitivity/recall 0.887218045113\n"
     ]
    }
   ],
   "source": [
    "# specify optimal hyperparameters\n",
    "best_params = {\"C\": 100, \"gamma\": 0.0001, \"kernel\":\"rbf\"}\n",
    "\n",
    "# model\n",
    "model = SVC(C=100, gamma=0.0001, kernel=\"rbf\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# metrics\n",
    "print(metrics.confusion_matrix(y_test, y_pred), \"\\n\")\n",
    "print(\"accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"sensitivity/recall\", metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The accuracy achieved using a non-linear kernel is comparable to that of a linear one. Thus, it turns out that for this problem, **you do not really need a non-linear kernel**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
